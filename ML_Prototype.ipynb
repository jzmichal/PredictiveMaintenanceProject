{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c96659f-84b1-4d6d-9469-c2b2e0284bdb",
   "metadata": {},
   "source": [
    "# Machine Learning Prototype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565c122-9bb0-4e38-868e-3302e518c110",
   "metadata": {},
   "source": [
    "We'll start off with a simple model like logistic regression. This is interpretable and explainable, so it should be a solid baseline to get an understanding before we move onto more complicated models.\n",
    "\n",
    "Because there is a major class imbalance of mostly samples that have not failed, we will implement stratified k-fold cross validation. This ensures that each fold maintains the same proportion of observations for each target class as the complete dataset.\n",
    "\n",
    "Additionally, because we saw earlier that some metrics have very high means and standard deviations, we will normalize these metrics. This will allow for the model to predict more accurately by not incorrectly weighing features more simply because they have potentially extreme values. \n",
    "\n",
    "Finally, as mentioned earlier, there is a strong class imbalance. In order to correct this, we will oversample. This makes it so that there are an equal number of failures as non failures in the training data. This is done by random sampling from the failure data until there an equal number of data points of both classes.\n",
    "\n",
    "Note, that since we are applying K-fold cross validation, it is important to apply the oversampling after we split the data with cross validation. If we do it before, i.e. oversample, then do k-fold cross validation, there will potentially be data leakage. This is because oversampling takes data that already exists and duplicates it. So there will be duplicate rows, thus potentially having one instance be in the training data, and one in the test data, which will lead to overfitting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53933cde-3411-47e1-86c3-7913a1ea5dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124488, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric1</th>\n",
       "      <th>log_m2</th>\n",
       "      <th>log_m3</th>\n",
       "      <th>log_m4</th>\n",
       "      <th>log_m8</th>\n",
       "      <th>log_m9</th>\n",
       "      <th>device_category</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>day_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215630672</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>S1F0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61370680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>S1F0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173295968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>S1F0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79694024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>S1F0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135970480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>S1F0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     metric1    log_m2    log_m3    log_m4  log_m8    log_m9 device_category  \\\n",
       "0  215630672  4.025352  0.000000  3.970292     0.0  2.079442            S1F0   \n",
       "1   61370680  0.000000  1.386294  0.000000     0.0  0.000000            S1F0   \n",
       "2  173295968  0.000000  0.000000  0.000000     0.0  0.000000            S1F0   \n",
       "3   79694024  0.000000  0.000000  0.000000     0.0  0.000000            S1F0   \n",
       "4  135970480  0.000000  0.000000  0.000000     0.0  1.386294            S1F0   \n",
       "\n",
       "   day  month  day_week  \n",
       "0    1      1         3  \n",
       "1    1      1         3  \n",
       "2    1      1         3  \n",
       "3    1      1         3  \n",
       "4    1      1         3  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonNumericColumns = [\"device\", \"date\", \"lastRecordedDate\"]\n",
    "\n",
    "engineered_df = df.drop(nonNumericColumns, axis = 1)\n",
    "\n",
    "X,y = engineered_df.drop(columns = [\"failure\"]), engineered_df.failure\n",
    "\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0094f14f-0fc7-4056-8079-034107cc5fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: failure, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7496cc-66f2-4fc5-aec1-3d059d345aa0",
   "metadata": {},
   "source": [
    "Below we're going to create a class specifically for the columns of our feature (X) matrix. We need to normalize metric1 of the data because it is so large, but not other metrics as they are ordinal categorical features. \n",
    "\n",
    "You may be wondering, why don't we just normalize that column right now, before we split the data into train and test? We don't do that because that will cause data leakage, i.e. the test data normalization for metric1 will have included our train data, which will skew our results and potentially lead to incorrect accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8baafdf8-0dc8-4122-9f4a-fa863e1e0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "numeric = ['metric1']\n",
    "categorical = ['log_m2', 'log_m3', 'log_m4', 'log_m8', 'log_m9', 'day', 'month', 'day_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bc8dd28-db0d-422a-be70-66b335cf96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X,y,OHE,low_card,scaler,i,sm):\n",
    "    samples = X.copy()\n",
    "    labels = y.copy()\n",
    "    \n",
    "    samples.reset_index(inplace = True, drop = True)\n",
    "    labels.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    if i == 1:\n",
    "        #Encoding categorical variables for train set\n",
    "        coding_hot = OHE.fit_transform(samples[low_card].to_numpy())\n",
    "        aux = pd.DataFrame(coding_hot, columns = OHE.get_feature_names_out(low_card))\n",
    "        samples = pd.concat([samples, aux], axis=1).drop(low_card, axis=1)\n",
    "        # Scaling as features\n",
    "        aux = scaler.fit_transform(samples)\n",
    "        samples = pd.DataFrame(aux,index= samples.index, columns= samples.columns)\n",
    "        xf, yf = sm.fit_resample(samples, labels) \n",
    "        \n",
    "    else:\n",
    "        #Encoding categorical variables for test set\n",
    "        coding_hot = OHE.transform(samples[low_card].to_numpy())\n",
    "        aux = pd.DataFrame(coding_hot, columns = OHE.get_feature_names_out(low_card))\n",
    "        samples = pd.concat([samples, aux], axis=1).drop(low_card, axis=1)\n",
    "        # Scaling as features\n",
    "        aux2 = scaler.transform(samples)\n",
    "        xf = pd.DataFrame(aux2,index=samples.index, columns=samples.columns)\n",
    "        yf = y\n",
    "    \n",
    "    return xf, yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81845178-fb03-4356-a0e6-f05ae1797eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)\n",
    "\n",
    "X_train.reset_index(inplace = True, drop = True)\n",
    "y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "X_test.reset_index(inplace = True, drop = True)\n",
    "y_test.reset_index(inplace = True, drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68dbff6f-808f-4d21-9490-7a2b1cb82038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric1</th>\n",
       "      <th>log_m2</th>\n",
       "      <th>log_m3</th>\n",
       "      <th>log_m4</th>\n",
       "      <th>log_m8</th>\n",
       "      <th>log_m9</th>\n",
       "      <th>device_category</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>day_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210331464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>W1F1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241893544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>W1F0</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159871712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.398163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>S1F0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243540872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>W1F1</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58172424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Z1F0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     metric1  log_m2    log_m3  log_m4  log_m8    log_m9 device_category  day  \\\n",
       "0  210331464     0.0  0.000000     0.0     0.0  0.000000            W1F1   10   \n",
       "1  241893544     0.0  0.000000     0.0     0.0  0.000000            W1F0   19   \n",
       "2  159871712     0.0  5.398163     0.0     0.0  3.218876            S1F0   16   \n",
       "3  243540872     0.0  0.000000     0.0     0.0  0.000000            W1F1   31   \n",
       "4   58172424     0.0  0.000000     0.0     0.0  0.000000            Z1F0    4   \n",
       "\n",
       "   month  day_week  \n",
       "0      1         5  \n",
       "1      7         6  \n",
       "2      1         4  \n",
       "3      5         6  \n",
       "4      1         6  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cac690ee-c00d-42f4-9c76-f04ec9e9e300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric1</th>\n",
       "      <th>log_m2</th>\n",
       "      <th>log_m3</th>\n",
       "      <th>log_m4</th>\n",
       "      <th>log_m8</th>\n",
       "      <th>log_m9</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>day_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.714100e+04</td>\n",
       "      <td>87141.000000</td>\n",
       "      <td>87141.000000</td>\n",
       "      <td>87141.000000</td>\n",
       "      <td>87141.000000</td>\n",
       "      <td>87141.000000</td>\n",
       "      <td>87141.000000</td>\n",
       "      <td>87141.000000</td>\n",
       "      <td>87141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.225075e+08</td>\n",
       "      <td>0.319076</td>\n",
       "      <td>0.177434</td>\n",
       "      <td>0.164197</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.396357</td>\n",
       "      <td>14.905831</td>\n",
       "      <td>4.027702</td>\n",
       "      <td>3.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.050994e+07</td>\n",
       "      <td>1.445548</td>\n",
       "      <td>0.822763</td>\n",
       "      <td>0.651295</td>\n",
       "      <td>0.299585</td>\n",
       "      <td>1.005679</td>\n",
       "      <td>8.750221</td>\n",
       "      <td>2.569862</td>\n",
       "      <td>1.999602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.138375e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.227866e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.836940e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.441405e+08</td>\n",
       "      <td>11.081666</td>\n",
       "      <td>7.898782</td>\n",
       "      <td>7.418781</td>\n",
       "      <td>6.725034</td>\n",
       "      <td>9.836386</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric1        log_m2        log_m3        log_m4        log_m8  \\\n",
       "count  8.714100e+04  87141.000000  87141.000000  87141.000000  87141.000000   \n",
       "mean   1.225075e+08      0.319076      0.177434      0.164197      0.031064   \n",
       "std    7.050994e+07      1.445548      0.822763      0.651295      0.299585   \n",
       "min    0.000000e+00      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    6.138375e+07      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    1.227866e+08      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    1.836940e+08      0.000000      0.000000      0.000000      0.000000   \n",
       "max    2.441405e+08     11.081666      7.898782      7.418781      6.725034   \n",
       "\n",
       "             log_m9           day         month      day_week  \n",
       "count  87141.000000  87141.000000  87141.000000  87141.000000  \n",
       "mean       0.396357     14.905831      4.027702      3.009938  \n",
       "std        1.005679      8.750221      2.569862      1.999602  \n",
       "min        0.000000      1.000000      1.000000      0.000000  \n",
       "25%        0.000000      7.000000      2.000000      1.000000  \n",
       "50%        0.000000     15.000000      3.000000      3.000000  \n",
       "75%        0.000000     22.000000      6.000000      5.000000  \n",
       "max        9.836386     31.000000     11.000000      6.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20555af8-3070-439e-b2a2-ff68135421b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric1            86783\n",
       "log_m2               487\n",
       "log_m3                45\n",
       "log_m4               104\n",
       "log_m8                26\n",
       "log_m9                64\n",
       "device_category        7\n",
       "day                   31\n",
       "month                 11\n",
       "day_week               7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f2d7530-4be4-44eb-8936-eb06090efeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['metric1', 'log_m2', 'log_m3', 'log_m4', 'log_m8', 'log_m9',\n",
      "       'device_category', 'day', 'month', 'day_week'],\n",
      "      dtype='object')\n",
      "(87141, 10)\n",
      "metric1              int64\n",
      "log_m2             float64\n",
      "log_m3             float64\n",
      "log_m4             float64\n",
      "log_m8             float64\n",
      "log_m9             float64\n",
      "device_category     object\n",
      "day                  int32\n",
      "month                int32\n",
      "day_week             int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n",
    "print(X_train.shape)\n",
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0b75739-747e-4d76-845c-38d01995d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "columns_to_encode = ['device_category']\n",
    "columns_to_scale  = ['metric1']\n",
    "\n",
    "OHE =  OneHotEncoder(handle_unknown = 'ignore',sparse_output=False)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Oversampler to help with class imbalance\n",
    "sm = SMOTE(random_state=0)\n",
    "\n",
    "#First drop any non numeric categories\n",
    "pipeline=ColumnTransformer([\n",
    "    ('num',scaler,columns_to_scale),\n",
    "    ('cat',OHE,columns_to_encode),\n",
    "    \n",
    "])\n",
    "\n",
    "new_X_train= pipeline.fit_transform(X_train)\n",
    "new_X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6e21379-ed0d-41ab-a932-59e42138446b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_m2</th>\n",
       "      <th>log_m3</th>\n",
       "      <th>log_m4</th>\n",
       "      <th>log_m8</th>\n",
       "      <th>log_m9</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>day_week</th>\n",
       "      <th>num__metric1</th>\n",
       "      <th>cat__device_category_S1F0</th>\n",
       "      <th>cat__device_category_S1F1</th>\n",
       "      <th>cat__device_category_W1F0</th>\n",
       "      <th>cat__device_category_W1F1</th>\n",
       "      <th>cat__device_category_Z1F0</th>\n",
       "      <th>cat__device_category_Z1F1</th>\n",
       "      <th>cat__device_category_Z1F2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.245562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.693190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.398163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.716553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.912431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_m2    log_m3  log_m4  log_m8    log_m9  day  month  day_week  \\\n",
       "0     0.0  0.000000     0.0     0.0  0.000000   10      1         5   \n",
       "1     0.0  0.000000     0.0     0.0  0.000000   19      7         6   \n",
       "2     0.0  5.398163     0.0     0.0  3.218876   16      1         4   \n",
       "3     0.0  0.000000     0.0     0.0  0.000000   31      5         6   \n",
       "4     0.0  0.000000     0.0     0.0  0.000000    4      1         6   \n",
       "\n",
       "   num__metric1  cat__device_category_S1F0  cat__device_category_S1F1  \\\n",
       "0      1.245562                        0.0                        0.0   \n",
       "1      1.693190                        0.0                        0.0   \n",
       "2      0.529917                        1.0                        0.0   \n",
       "3      1.716553                        0.0                        0.0   \n",
       "4     -0.912431                        0.0                        0.0   \n",
       "\n",
       "   cat__device_category_W1F0  cat__device_category_W1F1  \\\n",
       "0                        0.0                        1.0   \n",
       "1                        1.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        1.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   cat__device_category_Z1F0  cat__device_category_Z1F1  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        1.0                        0.0   \n",
       "\n",
       "   cat__device_category_Z1F2  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_columns = pipeline.get_feature_names_out()\n",
    "X_train_encoded = pd.DataFrame(new_X_train, index = X_train.index, columns=ohe_columns)\n",
    "X_test_encoded =  pd.DataFrame(new_X_test, index = X_test.index, columns=ohe_columns)\n",
    "\n",
    "X_train.drop(columns=[\"device_category\", \"metric1\"], inplace=True)\n",
    "X_test.drop(columns=[\"device_category\", \"metric1\"], inplace=True)\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_encoded], axis=1)\n",
    "\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db26d45d-31f3-4fec-8206-1b4f21eb682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure\n",
      "0    87072\n",
      "1    87072\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "544a1c9e-0cd6-4af7-b736-30f4e708b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174144, 16) (174144,)\n",
      "(37347, 16) (37347,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93360a93-b21f-452b-8cc1-3ef372ad294f",
   "metadata": {},
   "source": [
    "## Model Selection and Evaluation\n",
    "Given the imbalanced nature of our predictive maintenance dataset, where most data represents devices that have not failed, it's crucial to choose evaluation metrics that are robust to class imbalance and prioritize the correct identification of the minority class (failed devices) while minimizing false positives.\n",
    "\n",
    "We'll look at several different models to train on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4cd7aae9-90c3-4f81-a151-b57899ce1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a9fe0-95b0-49eb-a480-f576ce97f307",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier\n",
    "* Gradient Boosting Classifier is an ensemble learning method that combines multiple weak learners (typically decision trees) to create a strong predictive model.\n",
    "* It is effective at capturing complex interactions between features and target variables, making it suitable for predictive maintenance datasets with non-linear relationships and interactions.\n",
    "* Gradient Boosting can handle missing data and outliers effectively, which are common challenges in predictive maintenance datasets, and it automatically selects relevant features, reducing the need for manual feature engineering.\n",
    "#### Parameters:\n",
    "* n_estimators: The number of boosting stages (trees) to be used. Increasing this parameter generally improves performance at the cost of increased computational complexity.\n",
    "* learning_rate: The shrinkage parameter that controls the contribution of each tree to the final prediction. Smaller values require more trees to achieve comparable performance but may improve generalization.\n",
    "* max_depth: The maximum depth of the individual trees. This parameter controls the complexity of the trees and helps prevent overfitting.\n",
    "* min_samples_split and min_samples_leaf: These parameters control the minimum number of samples required to split an internal node and the minimum number of samples required to be at a leaf node, respectively. They help prevent overfitting by controlling tree complexity.\n",
    "* subsample: The fraction of samples to be used for fitting the individual base learners. It introduces randomness into the training process and can improve generalization.\n",
    "* max_features: The number of features to consider when looking for the best split. By tuning this parameter, we can control the randomness in feature selection for each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c6b3f32-7ef2-406f-90a2-4c9d84ced25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "# Define your parameter grid for Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# GridSearchCV with 5-fold cross-validation\n",
    "grid_search_gb = GridSearchCV(estimator=gb_classifier, param_grid=param_grid_gb, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_gb = grid_search_gb.best_params_\n",
    "\n",
    "# Predict labels for the test data\n",
    "y_pred_gb = grid_search_gb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e62acb-191e-4d66-a0dc-311842b65ab2",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "LR with 5 fold grid search cross-validation. Parameters:\n",
    "* C: Regularization parameter. Similar to LinearSVC, it controls the trade-off between fitting the training data and preventing overfitting.\n",
    "* penalty: The norm of the penalty used in regularization. Options include 'l1' (Lasso) and 'l2' (Ridge). These penalties can help reduce overfitting by shrinking the coefficients towards zero.\n",
    "* class_weight: Similar to LinearSVC, this parameter allows us to handle class imbalance by adjusting the penalty associated with misclassifying each class.\n",
    "* solver: The optimization algorithm to use. Different solvers have different characteristics and may perform differently depending on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60607466-012f-48a3-8f87-0cb5716810aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "# Define your parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression Classifier\n",
    "lr_classifier = LogisticRegression()\n",
    "\n",
    "# GridSearchCV with 5-fold cross-validation\n",
    "grid_search_lr = GridSearchCV(estimator=lr_classifier, param_grid=param_grid_lr, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "\n",
    "# Predict labels for the test data\n",
    "y_pred_lr = grid_search_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec753df-9935-4a74-85d5-56da054522dc",
   "metadata": {},
   "source": [
    "### Multi-Layer Neural Network with ReLU Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa5f54bd-ce47-496f-82ec-f81bb1e5e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0419\n",
      "Epoch [2/10], Loss: 0.0121\n",
      "Epoch [3/10], Loss: 0.0258\n",
      "Epoch [4/10], Loss: 0.0069\n",
      "Epoch [5/10], Loss: 0.0022\n",
      "Epoch [6/10], Loss: 0.0031\n",
      "Epoch [7/10], Loss: 0.0065\n",
      "Epoch [8/10], Loss: 0.0020\n",
      "Epoch [9/10], Loss: 0.0008\n",
      "Epoch [10/10], Loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Define your training data (X_train) and labels (y_train)\n",
    "# Define your testing data (X_test) and labels (y_test)\n",
    "\n",
    "# Convert your data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Define your neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)  # Assuming 2 classes for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize your neural network\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "model = NeuralNetwork(input_size)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "# Create DataLoader for training data\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, y_pred_nn = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18ab44e8-5a69-4416-8271-c26a25dcbe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Random Forest:\n",
      "Precision : 0.0833\n",
      "Recall : 0.027\n",
      "F1 Score : 0.0408\n",
      "Accuracy : 0.9987\n",
      "Specificity : 0.9997\n",
      "AUC-ROC : 0.5134\n",
      "AUC-PR : 0.0557\n",
      "\n",
      "Metrics for Gradient Boosting:\n",
      "Precision : 0.1667\n",
      "Recall : 0.0811\n",
      "F1 Score : 0.1091\n",
      "Accuracy : 0.9987\n",
      "Specificity : 0.9996\n",
      "AUC-ROC : 0.5403\n",
      "AUC-PR : 0.1243\n",
      "\n",
      "Metrics for SVM:\n",
      "Precision : 0.0\n",
      "Recall : 0.0\n",
      "F1 Score : 0.0\n",
      "Accuracy : 0.9958\n",
      "Specificity : 0.9968\n",
      "AUC-ROC : 0.4984\n",
      "AUC-PR : 0.0005\n",
      "\n",
      "Metrics for Logistic Regression:\n",
      "Precision : 0.0074\n",
      "Recall : 0.6216\n",
      "F1 Score : 0.0147\n",
      "Accuracy : 0.9173\n",
      "Specificity : 0.9176\n",
      "AUC-ROC : 0.7696\n",
      "AUC-PR : 0.3147\n",
      "\n",
      "Metrics for K-Nearest Neighbors:\n",
      "Precision : 0.0233\n",
      "Recall : 0.0541\n",
      "F1 Score : 0.0325\n",
      "Accuracy : 0.9968\n",
      "Specificity : 0.9977\n",
      "AUC-ROC : 0.5259\n",
      "AUC-PR : 0.0391\n",
      "\n",
      "Metrics for Neural Network:\n",
      "Precision : 0.0143\n",
      "Recall : 0.0541\n",
      "F1 Score : 0.0226\n",
      "Accuracy : 0.9954\n",
      "Specificity : 0.9963\n",
      "AUC-ROC : 0.5252\n",
      "AUC-PR : 0.0346\n",
      "\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=15.7min\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time= 9.2min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=22.4min\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time= 1.2min\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time= 1.2min\n",
      "[CV] END ....................C=1, gamma=auto, kernel=sigmoid; total time=17.5min\n",
      "[CV] END ..................C=10, gamma=scale, kernel=sigmoid; total time=23.4min\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=13.7min\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=15.7min\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time= 9.1min\n",
      "[CV] END ..................C=0.1, gamma=auto, kernel=sigmoid; total time=22.4min\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=14.5min\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time= 5.6min\n",
      "[CV] END ..................C=10, gamma=scale, kernel=sigmoid; total time=23.4min\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=13.7min\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time= 8.2min\n",
      "[CV] END .................C=0.1, gamma=scale, kernel=sigmoid; total time=21.9min\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=12.5min\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=14.4min\n",
      "[CV] END ....................C=1, gamma=auto, kernel=sigmoid; total time=16.8min\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=  36.8s\n",
      "[CV] END ...................C=10, gamma=auto, kernel=sigmoid; total time=24.2min\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.4s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# Define a dictionary to store evaluation metrics for each model\n",
    "evaluation_metrics = {}\n",
    "\n",
    "# Define a list of metrics to calculate\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'Accuracy', 'Specificity', 'AUC-ROC', 'AUC-PR']\n",
    "\n",
    "# Calculate metrics for each model\n",
    "for model_name, y_pred in zip(['Gradient Boosting', 'Logistic Regression', 'Neural Network'], \n",
    "                              [y_pred_gb, y_pred_lr, y_pred_nn]):\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    evaluation_metrics[model_name] = {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Accuracy': accuracy,\n",
    "        'Specificity': specificity,\n",
    "        'AUC-ROC': auc_roc,\n",
    "        'AUC-PR': auc_pr\n",
    "    }\n",
    "\n",
    "# Print metrics for each model\n",
    "for model_name, metrics_dict in evaluation_metrics.items():\n",
    "    print(f\"Metrics for {model_name}:\")\n",
    "    for metric_name, metric_value in metrics_dict.items():\n",
    "        print(metric_name, \":\",round(metric_value, 4))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eeacbe-d493-480b-be14-4c855e69f152",
   "metadata": {},
   "source": [
    "## Takeaways from each Metric\n",
    "\n",
    "* Precision (TPR): This can be thought of as the number of failed devices that were correctly predicted as faulted by our model, in relation to the to total number of devices were predicted to be faulted by our model. This was highest by far for gradient boosting, with a precision of 16.67%. So when looking at the total pool of samples predicted to be a \"1\", or faulted, about 16.67% of them were correct for the best model.\n",
    "\n",
    "* Recall. This can be seen as the number of devices that were correctly predicted to be faulted, in relation to the total number of devices that are actually faulted. This was highest by far with our logisitc regression model. So when looking at the total pool of faulted devices, in the best case, we identified 62% of them.\n",
    "\n",
    "* AUC-ROC: This is a measurement that takes into account both TPR and FPR. AUC-ROC can be biased towards the majority class when there is a class imbalance because it emphasizes false positives and true negatives. \n",
    "\n",
    "* AUC-PR: AUC-PR, on the other hand, focuses on the trade-off between precision and recall. AUC-PR is generally more informative when dealing with imbalanced datasets because it evaluates the classifier's performance based on positive class identification, which is often more critical in such scenarios\n",
    "\n",
    "* The Logisitic Regression Model dominated both of these metrics, of .77 and .31. Overall it had a much lower accuracy relative to the other models, which seems to indicate that it was more likely to a positive label (faulted) for samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389a67f-fba8-4e97-a6b8-88a9f98a6879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
